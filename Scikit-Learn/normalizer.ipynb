{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "# matplotlib 기반의 그래프를 출력 시 한글 사용을 위한 설정\n",
    "\n",
    "# system이 Mac이면,\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "\n",
    "# 음수를 사용하기 위함\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4472136  0.89442719]\n",
      " [0.5547002  0.83205029]\n",
      " [0.35112344 0.93632918]\n",
      " [0.89442719 0.4472136 ]\n",
      " [0.96152395 0.27472113]]\n"
     ]
    }
   ],
   "source": [
    "feature = np.array([[1, 2], [2, 3], [3, 8], [4, 2], [7, 2]])\n",
    "\n",
    "# 정규화 객체\n",
    "# L1를 norm에 적용하면 맨하튼 거리\n",
    "# L2를 norm에 적용하면 유클리드 거리 - 각 값을 전체 데이터를 제곱해서 더한 값의 제곱근으로 나눈 값\n",
    "# feature[1]: 1 / root(1^2 + 2^2), 2 / root(1^2 + 2^2)\n",
    "normalizer = preprocessing.Normalizer(norm='l2')\n",
    "l2_norm = normalizer.transform(feature)\n",
    "\n",
    "print(l2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   1.   2.   4.   1.   2.   4.   8.]\n",
      " [  2.   3.   4.   6.   9.   8.  12.  18.  27.]\n",
      " [  3.   8.   9.  24.  64.  27.  72. 192. 512.]\n",
      " [  4.   2.  16.   8.   4.  64.  32.  16.   8.]\n",
      " [  7.   2.  49.  14.   4. 343.  98.  28.   8.]]\n"
     ]
    }
   ],
   "source": [
    "feature = np.array([[1, 2], [2, 3], [3, 8], [4, 2], [7, 2]])\n",
    "\n",
    "# 제곱항까지의 다항을 생성 - 열의 개수가 늘어남\n",
    "# 회귀 분석할 때 시간의 흐름에 따라 변화가 급격하게 일어나는 경우\n",
    "# 데이터가 부족할 때 샘플 데이터를 추가하기 우해 사용\n",
    "# 제곱하거나 곱하기를 하면 데이터의 특성 자체는 크게 변화하지 않기 때문에 사용.\n",
    "\n",
    "polynomial = preprocessing.PolynomialFeatures(degree=3, include_bias=False)\n",
    "result = polynomial.fit_transform(feature)\n",
    "\n",
    "print(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [3 4]\n",
      " [4 9]\n",
      " [5 3]\n",
      " [8 3]]\n",
      "[[2 3]\n",
      " [3 4]\n",
      " [4 9]\n",
      " [5 3]\n",
      " [8 3]]\n"
     ]
    }
   ],
   "source": [
    "feature = np.array([[1, 2], [2, 3], [3, 8], [4, 2], [7, 2]])\n",
    "\n",
    "#위의 데이터에 함수 적용\n",
    "result1 = preprocessing.FunctionTransformer(lambda x : x + 1).transform(feature)\n",
    "print(result1)\n",
    "\n",
    "df = pd.DataFrame(feature, columns=[\"feature1\", \"feature2\"])\n",
    "print(df.apply(lambda x : x + 1).values)\n",
    "\n",
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "def sub_one(x):\n",
    "    return x - 1\n",
    "\n",
    "result2 = ColumnTransformer([   (\"add_one\", preprocessing.FunctionTransformer(add_one, validate=True), ['feature1']),\n",
    "                                (\"sub_one\", preprocessing.FunctionTransformer(sub_one, validate=True), ['feature2'])]).fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_mpg = pd.read_csv('../data/auto-mpg.csv', header=None)\n",
    "auto_mpg.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']\n",
    "\n",
    "auto_mpg['horsepower'].replace('?', np.nan, inplace=True)\n",
    "auto_mpg.dropna(subset=['horsepower'], axis=0, inplace=True)\n",
    "auto_mpg['horsepower'] = auto_mpg['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[257 103  32] [ 46.         107.33333333 168.66666667 230.        ]\n",
      "    horsepower hp_bin\n",
      "0        130.0  보통 출력\n",
      "1        165.0  보통 출력\n",
      "2        150.0  보통 출력\n",
      "3        150.0  보통 출력\n",
      "4        140.0  보통 출력\n",
      "5        198.0    고출력\n",
      "6        220.0    고출력\n",
      "7        215.0    고출력\n",
      "8        225.0    고출력\n",
      "9        190.0    고출력\n",
      "10       170.0    고출력\n",
      "11       160.0  보통 출력\n",
      "12       150.0  보통 출력\n",
      "13       225.0    고출력\n",
      "14        95.0    저출력\n",
      "15        95.0    저출력\n",
      "16        97.0    저출력\n",
      "17        85.0    저출력\n",
      "18        88.0    저출력\n",
      "19        46.0    저출력\n"
     ]
    }
   ],
   "source": [
    "# auto_mpg의 horsepower를 3개의 구간으로 분할\n",
    "auto_mpg['horsepower'].describe()\n",
    "\n",
    "# 경계값 찾기\n",
    "count, bin_dividers = np.histogram(auto_mpg['horsepower'], bins=3)\n",
    "\n",
    "print(count, bin_dividers)\n",
    "\n",
    "# 46.0 ~ 107.3 : 257개\n",
    "# 107.3 ~ 168.6 : 103개\n",
    "# 168.6 ~ 230.0 : 32개\n",
    "\n",
    "bin_names = ['저출력', '보통 출력', '고출력']\n",
    "\n",
    "auto_mpg['hp_bin'] = pd.cut(x = auto_mpg['horsepower'],\n",
    "                            bins=bin_dividers,\n",
    "                            labels=bin_names,\n",
    "                            include_lowest=True)\n",
    "print(auto_mpg[['horsepower', 'hp_bin']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 2 2 2 2 2 2 1 1 2 0 0 0 0 0 0 0 0 0 1 0 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 1 2 1 1 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 1 1 1 2 1 1 2 0 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 2 1 1 1 1 2 1 1 1 2 2 2 0 0 0 0 0 0 1 1 2 2 0 0 0 0 0\n",
      " 0 0 0 1 2 0 0 0 1 1 1 1 2 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 2 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 1 0 0 0 2 2 2 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "result = np.digitize(auto_mpg['horsepower'], bins=[107.33333333, 168.66666667, 230.0], right=True)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/preprocessing/_discretization.py:239: FutureWarning: In version 1.5 onwards, subsample=200_000 will be used by default. Set subsample explicitly to silence this warning in the mean time. Set subsample=None to disable subsampling explicitly.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# sklearn의 binning(구간 분할)\n",
    "\n",
    "age = np.array([[13], [30], [67], [36], [20], [33], [27]])\n",
    "\n",
    "binarizer = preprocessing.Binarizer(threshold=30.0)\n",
    "result = binarizer.transform(age)\n",
    "print(result)\n",
    "\n",
    "# 여러 개의 그룹으로 분할\n",
    "# 4개의 그룹으로 일련번호 형태로 일정한 비율 분할\n",
    "# strategy에 uniform을 설정하면간격을 일정하게 분할\n",
    "# encode 가 ordinal이면 일련변호로 그룹이 생성\n",
    "# onehot 을 설정하면 onehot, encoding을 한 후 최소 행렬로\n",
    "# onehot-dense 를 설정하면 onehot encoding을 한 후 밀집 행렬로.\n",
    "\n",
    "kb = preprocessing.KBinsDiscretizer(4, encode='ordinal', strategy='uniform')\n",
    "result = kb.fit_transform(age)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_1  feature_2\n",
      "0         13         30\n",
      "1         30         40\n",
      "2         67         44\n",
      "3         26         24\n",
      "4         22         11\n",
      "5         98         28\n",
      "   feature_1  feature_2  group\n",
      "0         13         30      1\n",
      "1         30         40      1\n",
      "2         67         44      2\n",
      "3         26         24      1\n",
      "4         22         11      1\n",
      "5         98         28      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sample = np.array([[13, 30], [30, 40], [67, 44], [26, 24], [22, 11], [98, 28]])\n",
    "df = pd.DataFrame(sample, columns= ['feature_1', 'feature_2'])\n",
    "print(df)\n",
    "\n",
    "cluster = KMeans(3, random_state = 42)\n",
    "cluster.fit(sample)\n",
    "df['group'] = cluster.predict(sample)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100008.5\n",
      "299997.16671570414\n",
      "[array([-0.33333148, -0.33333148, -0.33334148, -0.33334481, -0.33335481]), array([ 3.        , -0.33335481, -0.33328815, -0.33332481, -0.33332815])]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "def outliers_z_score(ys):\n",
    "    threshold = 3\n",
    "\n",
    "    mean_y = np.mean(ys)\n",
    "    stdev_y = np.std(ys)\n",
    "    z_scores = [(y - mean_y) / stdev_y for y in ys]\n",
    "    print(mean_y, stdev_y, z_scores, sep='\\n', end='\\n')\n",
    "    return np.where(np.abs(z_scores) > threshold)\n",
    "\n",
    "# 데이터가 12개 이하면 이상치가 없다고 판단함.\n",
    "feature = np.array([[10, 10, 7, 6, 3], [1000000, 3, 23, 12, 11]])\n",
    "print(outliers_z_score(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "299997.16671570414\n",
      "[array([ 0.00000000e+00,  0.00000000e+00, -6.74506370e-06, -8.99341827e-06,\n",
      "       -1.57384820e-05]), array([ 2.24833208e+00, -1.57384820e-05,  2.92286094e-05,  4.49670913e-06,\n",
      "        2.24835457e-06])]\n",
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "def outliers_z_score(ys):\n",
    "    threshold = 3.5\n",
    "\n",
    "    # 평균에서 중앙값으로 변경\n",
    "    # mean_y = np.mean(ys)\n",
    "    median_y = np.median(ys)\n",
    "    stdev_y = np.std(ys)\n",
    "    z_scores = [0.6745 * (y - median_y) / stdev_y for y in ys]\n",
    "    print(median_y, stdev_y, z_scores, sep='\\n', end='\\n')\n",
    "    return np.where(np.abs(z_scores) > threshold)\n",
    "\n",
    "# 데이터가 12개 이하면 이상치가 없다고 판단함.\n",
    "feature = np.array([[10, 10, 7, 6, 3], [1000000, 3, 23, 12, 11]])\n",
    "print(outliers_z_score(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 1, 1]), array([4, 0, 1, 2]))\n"
     ]
    }
   ],
   "source": [
    "def outliers_iqr(ys):\n",
    "    #1사분위수와 3사분위 수 구하기\n",
    "    quartile_1, quartile_3 = np.percentile(ys, [25, 75])\n",
    "    iqr = quartile_3 - quartile_1\n",
    "\n",
    "    lower_bound = quartile_1 - (iqr * 0.5)\n",
    "    upper_bound = quartile_3 + (iqr * 1.5)\n",
    "    return np.where((ys > upper_bound) | (ys < lower_bound))\n",
    "\n",
    "feature = np.array([[10, 10, 7, 6, 3], [1000000, 3, 23, 12, 11]])\n",
    "print(outliers_iqr(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.743351    8.78014917]\n",
      " [-3.4172217   7.60198243]\n",
      " [-3.52202874  9.32853346]\n",
      " [-2.26723535  7.10100588]\n",
      " [-2.97261532  8.54855637]\n",
      " [-1.04354885  8.78850983]\n",
      " [-1.86150908 10.53731598]\n",
      " [-2.97867201  9.55684617]\n",
      " [-4.23411546  8.4519986 ]\n",
      " [-0.92998481  9.78172086]]\n",
      "[[ 1.00000000e+04  1.00000000e+04]\n",
      " [-3.41722170e+00  7.60198243e+00]\n",
      " [-3.52202874e+00  9.32853346e+00]\n",
      " [-2.26723535e+00  7.10100588e+00]\n",
      " [-2.97261532e+00  8.54855637e+00]\n",
      " [-1.04354885e+00  8.78850983e+00]\n",
      " [-1.86150908e+00  1.05373160e+01]\n",
      " [-2.97867201e+00  9.55684617e+00]\n",
      " [-4.23411546e+00  8.45199860e+00]\n",
      " [-9.29984808e-01  9.78172086e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "feature, _ = make_blobs(n_samples=10, n_features=2, centers=1, random_state=42)\n",
    "print(feature)\n",
    "\n",
    "feature[0, 0] = 10000\n",
    "feature[0, 1] = 10000\n",
    "print(feature)\n",
    "outlier_detector = EllipticEnvelope(contamination=0.1)\n",
    "outlier_detector.fit(feature)\n",
    "\n",
    "# 이상치로 판단되면 -1을 리턴하고 그렇지 않으면 1을 리턴\n",
    "outlier_detector.predict(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Price  Rooms   Feet  Outlier\n",
      "0  5000000      2   1500        0\n",
      "1   390000      3   2000        0\n",
      "2   290000      5   1300        0\n",
      "3  5000000    116  20000        1\n",
      "     Price  Rooms   Feet  Outlier  Log_Feet\n",
      "0  5000000      2   1500        0  7.313220\n",
      "1   390000      3   2000        0  7.600902\n",
      "2   290000      5   1300        0  7.170120\n",
      "3  5000000    116  20000        1  9.903488\n",
      "     Price  Rooms   Feet  Outlier  Log_Feet  Scale_Rooms\n",
      "0  5000000      2   1500        0  7.313220    -0.066667\n",
      "1   390000      3   2000        0  7.600902    -0.033333\n",
      "2   290000      5   1300        0  7.170120     0.033333\n",
      "3  5000000    116  20000        1  9.903488     3.733333\n"
     ]
    }
   ],
   "source": [
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [5000000, 390000, 290000, 5000000]\n",
    "houses['Rooms'] = [2, 3, 5, 116]\n",
    "houses['Feet'] = [1500, 2000, 1300, 20000]\n",
    "\n",
    "# rooms 값이 20보다 크면 이상치로 간주하고 특성을 추가\n",
    "houses['Outlier'] = np.where(houses['Rooms'] > 20, 1, 0)\n",
    "print(houses)\n",
    "\n",
    "houses['Log_Feet'] = [np.log(x) for x in houses['Feet']]\n",
    "print(houses)\n",
    "\n",
    "# Outlier의 영향향을 최소화 - 특성 변환(Scaling)\n",
    "imsi = pd.DataFrame(houses['Rooms'])\n",
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(imsi)\n",
    "houses['Scale_Rooms'] = scaler.transform(imsi)\n",
    "print(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "titainic = sns.load_dataset('titanic')\n",
    "print(titainic.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
      "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "0      man        True  NaN  Southampton    no  False  \n",
      "1    woman       False    C    Cherbourg   yes  False  \n",
      "2    woman       False  NaN  Southampton   yes   True  \n",
      "3    woman       False    C  Southampton   yes  False  \n",
      "4      man        True  NaN  Southampton    no   True  \n",
      "..     ...         ...  ...          ...   ...    ...  \n",
      "886    man        True  NaN  Southampton    no   True  \n",
      "887  woman       False    B  Southampton   yes   True  \n",
      "888  woman       False  NaN  Southampton    no  False  \n",
      "889    man        True    C    Cherbourg   yes   True  \n",
      "890    man        True  NaN   Queenstown    no   True  \n",
      "\n",
      "[891 rows x 15 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 714 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     714 non-null    int64   \n",
      " 1   pclass       714 non-null    int64   \n",
      " 2   sex          714 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        714 non-null    int64   \n",
      " 5   parch        714 non-null    int64   \n",
      " 6   fare         714 non-null    float64 \n",
      " 7   embarked     712 non-null    object  \n",
      " 8   class        714 non-null    category\n",
      " 9   who          714 non-null    object  \n",
      " 10  adult_male   714 non-null    bool    \n",
      " 11  deck         184 non-null    category\n",
      " 12  embark_town  712 non-null    object  \n",
      " 13  alive        714 non-null    object  \n",
      " 14  alone        714 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 70.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 결측치 삭제\n",
    "# 각 컬럼의 None의 개수를 파악함.\n",
    "print(titainic.isnull().sum(axis=0))\n",
    "\n",
    "# 결측치의 개수가 200 개 이상인 컬럼 삭제\n",
    "titainic_thresh = titainic.dropna(axis=1, thresh=200)\n",
    "print(titainic_thresh)\n",
    "\n",
    "result = titainic_thresh[['survived', 'pclass', 'sex', 'age', 'sibsp']]\n",
    "\n",
    "# 결측치인 행만 제거함\n",
    "result_age = titainic.dropna(subset=['age'], how='any', axis=0)\n",
    "result_age.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "830      Cherbourg\n",
      "Name: embark_town, dtype: object\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829            NaN\n",
      "830      Cherbourg\n",
      "Name: embark_town, dtype: object\n",
      "825     Queenstown\n",
      "826    Southampton\n",
      "827      Cherbourg\n",
      "828     Queenstown\n",
      "829    Southampton\n",
      "830      Cherbourg\n",
      "Name: embark_town, dtype: object\n"
     ]
    }
   ],
   "source": [
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "print(titanic['embark_town'][825:831])\n",
    "titanic['embark_town'].fillna(method='ffill')\n",
    "print(titanic['embark_town'][825:831])\n",
    "\n",
    "# 결측치가 몇 개 되지 않을 때는 대표값으로 대체\n",
    "# 대표값으로 사용될 수 있는 데이터는 평균, 중간값, 최빈값 등\n",
    "# 대표값으로 변환하는 경우 많은 양의 데이터를 변경하면 분석할 때 결과가 왜곡될 수 있음.\n",
    "\n",
    "mode = titanic['embark_town'].value_counts()\n",
    "# 가장 많이 출현한 데이터\n",
    "# pirnt(mode. idxmax())\n",
    "titanic['embark_town'].fillna(mode.idxmax(), inplace=True)\n",
    "print(titanic['embark_town'][825:831])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100.]\n",
      " [200.]\n",
      " [300.]\n",
      " [400.]\n",
      " [500.]\n",
      " [300.]]\n"
     ]
    }
   ],
   "source": [
    "# sklearn 의 SimpleImputer 이용\n",
    "# 객체를 만들 때 strategy 옵션에 mean, median, most_frequent, constant를 설정\n",
    "# constant를 설정하면 fill_value 옵션에 채울 값을 추가해우어야 한다.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "features = np.array([[100], [200], [300], [400], [500], [np.nan]])\n",
    "\n",
    "# NaN값을 중간값으로 대체함.\n",
    "simple_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "print(simple_imputer.fit_transform(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+04  1.00000000e+04]\n",
      " [-3.41722170e+00  7.60198243e+00]\n",
      " [-3.52202874e+00  9.32853346e+00]\n",
      " [-2.26723535e+00  7.10100588e+00]\n",
      " [-2.97261532e+00  8.54855637e+00]\n",
      " [-1.04354885e+00  8.78850983e+00]\n",
      " [-1.86150908e+00  1.05373160e+01]\n",
      " [-2.97867201e+00  9.55684617e+00]\n",
      " [-4.23411546e+00  8.45199860e+00]\n",
      " [-9.29984808e-01  9.78172086e+00]]\n",
      "[[ 1.00000000e+04  1.00000000e+04]\n",
      " [-3.41722170e+00  7.60198243e+00]\n",
      " [-3.52202874e+00  9.32853346e+00]\n",
      " [-2.26723535e+00  7.10100588e+00]\n",
      " [-2.97261532e+00  8.54855637e+00]\n",
      " [-1.04354885e+00  8.78850983e+00]\n",
      " [-1.86150908e+00  1.05373160e+01]\n",
      " [-2.97867201e+00  9.55684617e+00]\n",
      " [-4.23411546e+00  8.45199860e+00]\n",
      " [-9.29984808e-01  9.78172086e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/fancyimpute/solver.py:55: UserWarning: Input matrix is not missing any values\n",
      "  warnings.warn(\"Input matrix is not missing any values\")\n"
     ]
    }
   ],
   "source": [
    "from fancyimpute import KNN\n",
    "\n",
    "features = np.array([[100, 200], [200, 400], [300, 600], [400, 800], [200, np.nan]])\n",
    "print(KNN(k=5, verbose=0).fit_transform(feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
