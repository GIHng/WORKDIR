{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "import platform\n",
    "\n",
    "\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "# Jupyter Notebook의 출력을 소수점 이하 3자리로 제한 \n",
    "%precision 3\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "# 데이터를 분할할 때 동일한 분할을 만들기 위해서\n",
    "# 모델을 만드는 작업을 여러 번에 걸쳐서 하는 경우 시드가 변경되면\n",
    "# 훈련용 데이터가 자주 변경되면 결국 모든 데터를 가지고 모델을 생성하는 결과\n",
    "# Outfit을 만드는 효과를 가져옴.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.831 -0.259]\n",
      " [ 1.185  0.92 ]\n",
      " [ 1.164 -0.456]\n",
      " [-0.024  1.086]\n",
      " [ 0.481  1.509]]\n",
      "[1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(X[0:5])\n",
    "print(y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(random_state=42)),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                             (&#x27;svc&#x27;, SVC(random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression(random_state=42)),\n",
       "                             (&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
       "                             (&#x27;svc&#x27;, SVC(random_state=42))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression     \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingaClassifier\n",
    "\n",
    "log_clf = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "svc_clf = SVC(gamma='scale', random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('lr', log_clf), ('rf', rnd_clf), ('svc', svc_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 정확도: 0.864\n",
      "SVC 정확도: 0.896\n",
      "RandomForestClassifier 정확도: 0.896\n",
      "VotingClassifier 정확도: 0.912\n"
     ]
    }
   ],
   "source": [
    "# 각 모델의 정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, svc_clf, rnd_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, \"정확도:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.896\n",
      "VotingClassifier 0.92\n"
     ]
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oob 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.899"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, oob_score=True, random_state=40)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.323, 0.677],\n",
       "       [0.341, 0.659],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.095, 0.905],\n",
       "       [0.311, 0.689],\n",
       "       [0.018, 0.982],\n",
       "       [0.971, 0.029],\n",
       "       [0.978, 0.022],\n",
       "       [0.744, 0.256],\n",
       "       [0.   , 1.   ],\n",
       "       [0.717, 0.283],\n",
       "       [0.85 , 0.15 ],\n",
       "       [0.972, 0.028],\n",
       "       [0.062, 0.938],\n",
       "       [0.   , 1.   ],\n",
       "       [0.978, 0.022],\n",
       "       [0.946, 0.054],\n",
       "       [1.   , 0.   ],\n",
       "       [0.017, 0.983],\n",
       "       [0.395, 0.605],\n",
       "       [0.887, 0.113],\n",
       "       [1.   , 0.   ],\n",
       "       [0.978, 0.022],\n",
       "       [0.   , 1.   ],\n",
       "       [0.994, 0.006],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.626, 0.374],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.134, 0.866],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.383, 0.617],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.271, 0.729],\n",
       "       [0.341, 0.659],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.005, 0.995],\n",
       "       [0.988, 0.012],\n",
       "       [0.914, 0.086],\n",
       "       [0.973, 0.027],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.074, 0.926],\n",
       "       [0.98 , 0.02 ],\n",
       "       [0.005, 0.995],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.978, 0.022],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.424, 0.576],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.665, 0.335],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.868, 0.132],\n",
       "       [1.   , 0.   ],\n",
       "       [0.567, 0.433],\n",
       "       [0.158, 0.842],\n",
       "       [0.665, 0.335],\n",
       "       [0.917, 0.083],\n",
       "       [0.   , 1.   ],\n",
       "       [0.168, 0.832],\n",
       "       [0.874, 0.126],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.995, 0.005],\n",
       "       [0.   , 1.   ],\n",
       "       [0.079, 0.921],\n",
       "       [0.054, 0.946],\n",
       "       [0.29 , 0.71 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.83 , 0.17 ],\n",
       "       [0.011, 0.989],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.215, 0.785],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.947, 0.053],\n",
       "       [0.771, 0.229],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.166, 0.834],\n",
       "       [0.653, 0.347],\n",
       "       [0.   , 1.   ],\n",
       "       [0.026, 0.974],\n",
       "       [0.506, 0.494],\n",
       "       [1.   , 0.   ],\n",
       "       [0.032, 0.968],\n",
       "       [0.994, 0.006],\n",
       "       [0.237, 0.763],\n",
       "       [0.495, 0.505],\n",
       "       [0.995, 0.005],\n",
       "       [0.006, 0.994],\n",
       "       [0.99 , 0.01 ],\n",
       "       [0.262, 0.738],\n",
       "       [0.93 , 0.07 ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.801, 0.199],\n",
       "       [1.   , 0.   ],\n",
       "       [0.011, 0.989],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.982, 0.018],\n",
       "       [1.   , 0.   ],\n",
       "       [0.01 , 0.99 ],\n",
       "       [0.978, 0.022],\n",
       "       [0.995, 0.005],\n",
       "       [0.02 , 0.98 ],\n",
       "       [0.179, 0.821],\n",
       "       [0.984, 0.016],\n",
       "       [0.295, 0.705],\n",
       "       [0.983, 0.017],\n",
       "       [0.   , 1.   ],\n",
       "       [0.006, 0.994],\n",
       "       [0.757, 0.243],\n",
       "       [0.386, 0.614],\n",
       "       [0.406, 0.594],\n",
       "       [0.874, 0.126],\n",
       "       [0.925, 0.075],\n",
       "       [0.052, 0.948],\n",
       "       [0.828, 0.172],\n",
       "       [0.015, 0.985],\n",
       "       [0.   , 1.   ],\n",
       "       [0.023, 0.977],\n",
       "       [0.973, 0.027],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.01 , 0.99 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.038, 0.962],\n",
       "       [0.02 , 0.98 ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.949, 0.051],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.995, 0.005],\n",
       "       [0.   , 1.   ],\n",
       "       [0.394, 0.606],\n",
       "       [0.332, 0.668],\n",
       "       [0.006, 0.994],\n",
       "       [0.   , 1.   ],\n",
       "       [0.317, 0.683],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.006, 0.994],\n",
       "       [0.   , 1.   ],\n",
       "       [0.989, 0.011],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.629, 0.371],\n",
       "       [0.923, 0.077],\n",
       "       [0.   , 1.   ],\n",
       "       [0.995, 0.005],\n",
       "       [1.   , 0.   ],\n",
       "       [0.989, 0.011],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.07 , 0.93 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.036, 0.964],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.022, 0.978],\n",
       "       [1.   , 0.   ],\n",
       "       [0.958, 0.042],\n",
       "       [0.784, 0.216],\n",
       "       [0.567, 0.433],\n",
       "       [0.   , 1.   ],\n",
       "       [0.18 , 0.82 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.931, 0.069],\n",
       "       [0.972, 0.028],\n",
       "       [1.   , 0.   ],\n",
       "       [0.005, 0.995],\n",
       "       [0.   , 1.   ],\n",
       "       [0.43 , 0.57 ],\n",
       "       [0.859, 0.141],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.006, 0.994],\n",
       "       [0.   , 1.   ],\n",
       "       [0.969, 0.031],\n",
       "       [0.   , 1.   ],\n",
       "       [0.216, 0.784],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.985, 0.015],\n",
       "       [0.8  , 0.2  ],\n",
       "       [0.994, 0.006],\n",
       "       [0.   , 1.   ],\n",
       "       [0.095, 0.905],\n",
       "       [0.995, 0.005],\n",
       "       [0.017, 0.983],\n",
       "       [0.   , 1.   ],\n",
       "       [0.027, 0.973],\n",
       "       [1.   , 0.   ],\n",
       "       [0.77 , 0.23 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.902, 0.098],\n",
       "       [0.984, 0.016],\n",
       "       [0.222, 0.778],\n",
       "       [0.203, 0.797],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.203, 0.797],\n",
       "       [0.982, 0.018],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.99 , 0.01 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.487, 0.513],\n",
       "       [1.   , 0.   ],\n",
       "       [0.005, 0.995],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.084, 0.916],\n",
       "       [0.124, 0.876],\n",
       "       [0.994, 0.006],\n",
       "       [0.035, 0.965],\n",
       "       [1.   , 0.   ],\n",
       "       [0.398, 0.602],\n",
       "       [0.054, 0.946],\n",
       "       [0.532, 0.468],\n",
       "       [0.519, 0.481],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.609, 0.391],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.242, 0.758],\n",
       "       [0.816, 0.184],\n",
       "       [0.087, 0.913],\n",
       "       [0.995, 0.005],\n",
       "       [0.821, 0.179],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.119, 0.881],\n",
       "       [0.042, 0.958],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.892, 0.108],\n",
       "       [0.192, 0.808],\n",
       "       [0.952, 0.048],\n",
       "       [0.005, 0.995],\n",
       "       [0.594, 0.406],\n",
       "       [0.077, 0.923],\n",
       "       [0.995, 0.005],\n",
       "       [0.837, 0.163],\n",
       "       [0.   , 1.   ],\n",
       "       [0.995, 0.005],\n",
       "       [0.954, 0.046],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.264, 0.736],\n",
       "       [0.985, 0.015],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.006, 0.994],\n",
       "       [0.851, 0.149],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.753, 0.247],\n",
       "       [0.897, 0.103],\n",
       "       [1.   , 0.   ],\n",
       "       [0.756, 0.244],\n",
       "       [0.489, 0.511],\n",
       "       [0.   , 1.   ],\n",
       "       [0.925, 0.075],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.877, 0.123],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.748, 0.252],\n",
       "       [0.091, 0.909],\n",
       "       [0.423, 0.577],\n",
       "       [0.224, 0.776],\n",
       "       [0.   , 1.   ],\n",
       "       [0.87 , 0.13 ],\n",
       "       [0.782, 0.218],\n",
       "       [0.005, 0.995],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.029, 0.971],\n",
       "       [0.96 , 0.04 ],\n",
       "       [0.935, 0.065],\n",
       "       [1.   , 0.   ],\n",
       "       [0.507, 0.493],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.016, 0.984],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.97 , 0.03 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.052, 0.948],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.995, 0.005],\n",
       "       [0.017, 0.983],\n",
       "       [1.   , 0.   ],\n",
       "       [0.146, 0.854],\n",
       "       [0.   , 1.   ],\n",
       "       [0.005, 0.995],\n",
       "       [0.   , 1.   ],\n",
       "       [0.418, 0.582],\n",
       "       [0.131, 0.869],\n",
       "       [0.221, 0.779],\n",
       "       [1.   , 0.   ],\n",
       "       [0.976, 0.024],\n",
       "       [0.212, 0.788],\n",
       "       [0.989, 0.011],\n",
       "       [0.   , 1.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.964, 0.036],\n",
       "       [0.346, 0.654],\n",
       "       [0.982, 0.018],\n",
       "       [1.   , 0.   ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.995, 0.005],\n",
       "       [0.   , 1.   ],\n",
       "       [0.06 , 0.94 ],\n",
       "       [0.982, 0.018],\n",
       "       [1.   , 0.   ],\n",
       "       [0.031, 0.969],\n",
       "       [0.589, 0.411]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 클래스 확률\n",
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정확도\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#배깅을 이용한 random forest 만들기\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
    "    n_estimators=500, random_state=42)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest 분류기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(y_pred == y_pred_rf) / len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
