{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'do', 'hate', 'i', 'like', 'love', 'not', 'you'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련 데이터 생성\n",
    "### 단어별 분류를 위한 패키지 import\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "### 훈련 데이터 만들기\n",
    "train = [('i like you', 'pos'), \n",
    "         ('i do not like you', 'neg'),\n",
    "         ('i hate you', 'neg'), \n",
    "         ('i do not hate you', 'pos'),\n",
    "        ('i love you', 'pos'),\n",
    "        ('I do not love you', 'neg')]\n",
    "\n",
    "# 여러 번 등장하는 것은 일상에서 사용하는 관융구일 가능성이 높음.\n",
    "\n",
    "all_words = set(word.lower() for sentence in train \n",
    "            for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'do': False, 'not': False, 'you': True, 'love': False, 'like': True, 'i': True, 'hate': False}, 'pos'), ({'do': True, 'not': True, 'you': True, 'love': False, 'like': True, 'i': True, 'hate': False}, 'neg'), ({'do': False, 'not': False, 'you': True, 'love': False, 'like': False, 'i': True, 'hate': True}, 'neg'), ({'do': True, 'not': True, 'you': True, 'love': False, 'like': False, 'i': True, 'hate': True}, 'pos'), ({'do': False, 'not': False, 'you': True, 'love': True, 'like': False, 'i': True, 'hate': False}, 'pos'), ({'do': True, 'not': True, 'you': True, 'love': True, 'like': False, 'i': False, 'hate': False}, 'neg')]\n",
      "Most Informative Features\n",
      "                      do = False             pos : neg    =      1.7 : 1.0\n",
      "                      do = True              neg : pos    =      1.7 : 1.0\n",
      "                     not = False             pos : neg    =      1.7 : 1.0\n",
      "                     not = True              neg : pos    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.4 : 1.0\n",
      "                    hate = False             neg : pos    =      1.0 : 1.0\n",
      "                    hate = True              neg : pos    =      1.0 : 1.0\n",
      "                    like = False             neg : pos    =      1.0 : 1.0\n",
      "                    like = True              neg : pos    =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1]) for x in train]\n",
    "\n",
    "print(t)\n",
    "\n",
    "classifier = nltk.NaiveBayesClassifier.train(t)\n",
    "classifier.show_most_informative_features()\n",
    "\n",
    "# hate와 like는 긍정과 부정이 반반이기 때문에 빼는 것이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'do': True, 'not': True, 'you': False, 'love': False, 'like': True, 'i': True, 'hate': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'i do not like jessica'\n",
    "\n",
    "test_sentence_feature = {word.lower():(word in word_tokenize(test_sentence.lower())) for word in all_words}\n",
    "\n",
    "print(test_sentence_feature)\n",
    "\n",
    "classifier.classify(test_sentence_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 감성 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [('나는 당신을 사랑합니다', 'pos'), ('나는 당신을 사랑하지 않아요', 'neg',),\n",
    "         ('나는 당신을 만나는 것이 지루합니다', 'neg'), ('나는 당신이 좋아요', 'pos'),\n",
    "         ('나는 노는 것이 좋습니다', 'pos'), ('나는 일을 하는 것이 즐겁습니다', 'neg'),\n",
    "         ('맛있는 것을 먹으면 행복합니다', 'pos'), ('오늘은 서점에 갈 예정입니다', 'pos'),\n",
    "         ('오늘 점심은 햄버거가 어떨까요', 'pos')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'갈',\n",
       " '것을',\n",
       " '것이',\n",
       " '나는',\n",
       " '노는',\n",
       " '당신을',\n",
       " '당신이',\n",
       " '만나는',\n",
       " '맛있는',\n",
       " '먹으면',\n",
       " '사랑하지',\n",
       " '사랑합니다',\n",
       " '서점에',\n",
       " '않아요',\n",
       " '어떨까요',\n",
       " '예정입니다',\n",
       " '오늘',\n",
       " '오늘은',\n",
       " '일을',\n",
       " '점심은',\n",
       " '좋습니다',\n",
       " '좋아요',\n",
       " '즐겁습니다',\n",
       " '지루합니다',\n",
       " '하는',\n",
       " '햄버거가',\n",
       " '행복합니다'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_words = set(word.lower() for sentence in train \n",
    "            for word in word_tokenize(sentence[0]))\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
